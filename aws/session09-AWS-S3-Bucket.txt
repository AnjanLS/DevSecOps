AWS-S3(simple-storage-service)
------------------------------

Note: most of the times we store the Info in the physical drives for the personal usage but the organisations we will deal with 
      databases, dumps, continous backups, application logs, dashboards, charts, Info for the things like .csv, excel all of these 
	  things will store in the cloud. S3 is globally accessible using the HTTPS protocol. The secret behind the AWS success is(11 9's)
	  99.99999999999% is reliable. without bucket versioning If we upload the same file within the same folder it will replace the file.
	  Even If someone have access to s3 bucket from the IAM rules even though we can restrict them by using s3 permissions.

1. what is Amazon S3?
-> Simple Storage Service is a scalable, Highly available, performance, cost-effective and secure cloud storage service provided by 
   Amazon Web Services (AWS). It allows you to store and retrieve any amount of data from anywhere on the web.
   
2. What are S3 buckets?
-> S3 buckets are containers for storing objects (files) in Amazon S3. Each bucket has a unique name globally across all of AWS. You can
   think of an S3 bucket as a top-level folder that holds your data like pictures, videos, documents and files etc.

3. Why use S3 buckets?
-> S3 buckets provide a reliable and highly scalable storage solution for various use cases. They are commonly used for backup and 
   restore, data archiving, content storage for websites, and as a data source for big data analytics.

4. Key benefits of S3 buckets
-> S3 buckets offer several advantages, including:
   Durability and availability: S3 provides high durability and availability for your data.
   Scalability: You can store and retrieve any amount of data without worrying about capacity constraints.
   Security: S3 offers multiple security features such as encryption, access control, and audit logging.
   Performance: S3 is designed to deliver high performance for data retrieval and storage operations.
   Cost-effective: S3 offers cost-effective storage options and pricing models based on your usage patterns.

5. Creating and Configuring S3 Buckets
-> To create an S3 bucket, you can use the AWS Management Console, AWS CLI (Command Line Interface), or AWS SDKs (Software Development 
   Kits). You need to specify a globally unique bucket name and select the region where you want to create the bucket.
   Choosing a bucket name and region. The bucket name must be unique across all existing bucket names in Amazon S3. It should follow DNS
   naming conventions, be 3-63 characters long, and contain only lowercase letters, numbers, periods, and hyphens. The region selection 
   affects data latency and compliance with specific regulations.
   Bucket properties and configurations:
   Versioning: Versioning allows you to keep multiple versions of an object in the bucket. It helps protect against accidental deletions
   or overwrites.
   Bucket-level permissions and policies: define who can access and perform actions on the bucket. You can grant permissions using IAM 
   (Identity and Access Management) policies, which allow fine-grained control over user access to the bucket and its objects.

6. Uploading and Managing Objects in S3 Buckets
-> You can upload objects to an S3 bucket using various methods, including the AWS Management Console, AWS CLI, SDKs, and direct HTTP 
   uploads. Each object is assigned a unique key (name) within the bucket to retrieve it later.
   
   Object metadata and properties:
   Object metadata contains additional information abouteach object in an S3 bucket. It includes attributes like content type, cache 
   control, encryption settings, and custom metadata. These properties help in managing and organizing objects within the bucket.
   
   File formats and object encryption:
   S3 supports various file formats, including text files, images, videos, and more. You can encrypt objects stored in S3 using 
   server-side encryption (SSE). SSE options include SSE-S3 (Amazon-managed keys), SSE-KMS (AWS Key Management Service), and SSE-C 
   (customer-provided keys).
   
   Lifecycle management:
   Lifecycle management allows you to define rules for transitioning objects between different storage classes or deleting them 
   automatically based on predefined criteria. For example, you can move infrequently accessed data to a lower-cost storage class after 
   a specified time or delete objects after a certain retention period.
   
   Multipart uploads:
   Multipart uploads provide a mechanism for uploading large objects in parts, which improves performance and resiliency. You can upload
   each part in parallel and then combine them to create the complete object. Multipart uploads also enable resumable uploads in case of
   failures.
   
   Managing large datasets with S3 Batch Operations:
   S3 Batch Operations is a feature that allows you to perform bulk operations on large numbers of objects in an S3 bucket. It provides 
   an efficient way to automate tasks such as copying objects, tagging, and restoring archived data.
   
7. Advanced S3 Bucket Features
-> S3 Storage Classes
   S3 offers multiple storage classes, each designed for different use cases and performance requirements: 
| **Feature**                  | **S3 Standard** | **S3 Standard-IA** | **One Zone-IA** | **S3 Glacier** | **S3 Glacier Instant Retrieval** | **S3 Glacier Flexible Retrieval** | **S3 Glacier Deep Archive** | **S3 Outposts** | **S3 Intelligent-Tiering** |
| ---------------------------- | --------------- | ------------------ | --------------- | -------------- | -------------------------------- | --------------------------------- | --------------------------- | --------------- | -------------------------- |
| **Cost per GB per month**    | \$0.02          | \$0.01             | \$0.01          | \$0.00         | \$0.00                           | \$0.00                            | \$0.00                      | \$0.03          | \$0.015–0.025              |
| **Access time**              | 1–15 seconds    | 3–5 minutes        | 3–5 minutes     | 12–48 hours    | 1–5 minutes                      | 1–5 minutes                       | 12–48 hours                 | Varies          | Varies                     |
| **Durability**               | 100.00%         | 100.00%            | 100.00%         | 100.00%        | 100.00%                          | 100.00%                           | 100.00%                     | 100.00%         | 100.00%                    |
| **Availability**             | 99.90%          | 99.90%             | 99.90%          | 99.90%         | 99.90%                           | 99.90%                            | 99.90%                      | 99.90%          | 99.90%                     |
| **Minimum storage duration** | Varies          | Varies             | Varies          | Varies         | Varies                           | Varies                            | Varies                      | Varies          | Varies                     |

   S3 Replication: S3 replication enables automatic and asynchronous replication of objects between S3 buckets in different regions or 
   within the same region. Cross-Region Replication (CRR) provides disaster recovery and compliance benefits, while Same-Region 
   Replication (SRR) can be used for data resilience and low-latency access.

   S3 Event Notifications and Triggers: S3 event notifications allow you to configure actions when specific events occur in an S3 
   bucket. For example, you can trigger AWS Lambda functions, send messages to Amazon Simple Queue Service (SQS), or invoke other 
   services using Amazon SNS when an object is created or deleted.

   S3 Batch Operations: S3 Batch Operations allow you to perform large-scale batch operations on objects, such as copying, tagging, or 
   deleting, across multiple buckets. It simplifies managing large datasets and automates tasks that would otherwise be time-consuming.
   
8. Security and Compliance in S3 Buckets
-> S3 bucket security considerations: Ensure that S3 bucket policies, access control, and encryption settings are appropriately 
   configured. Regularly monitor and audit access logs for unauthorized activities.
   
   Data encryption at rest and in transit: Encrypt data at rest using server-side encryption options provided by S3. Additionally, 
   enable encryption in transit by using SSL/TLS for data transfers.

   Access logging and monitoring: Enable access logging to capture detailed records of requests made to your S3 bucket. Monitor access 
   logs and configure alerts to detect any suspicious activities or unauthorized access attempts.
   
9. S3 Bucket Management and Administration
-> S3 bucket policies: Create and manage bucket policies to control access to your S3 buckets. Bucket policies are written in JSON and 
   define permissions for various actions and resources.

   S3 access control and IAM roles: Use IAM roles and policies to manage access to S3 buckets. IAM roles provide temporary credentials 
   and fine-grained access control to AWS resources.

   S3 APIs and SDKs: Interact with S3 programmatically using AWS SDKs or APIs. These provide libraries and methods for performing 
   various operations on S3 buckets and objects.

   Monitoring and logging with CloudWatch: Utilize Amazon CloudWatch to monitor S3 metrics, set up alarms for specific events, and 
   collect and analyze logs for troubleshooting and performance optimization.

  S3 management tools: AWS provides multiple management tools, such as the AWS Management Console, AWS CLI, and third-party tools, to 
  manage S3 buckets efficiently and perform operations like uploads, downloads, and bucket configurations.
  
10. Troubleshooting and Error Handling
-> Common S3 error messages and their resolutions: Understand common S3 error messages like access denied, bucket not found, and 
   exceeded bucket quota. Troubleshoot and resolve these errors by checking permissions, bucket configurations, and network connectivity.

   Debugging S3 bucket access issues: Investigate and resolve issues related to access permissions, IAM roles, and bucket policies. Use 
   tools like AWS CloudTrail and S3 access logs to identify and troubleshoot access problems.

   Data consistency and durability considerations: Ensure data consistency and durability by understanding S3's data replication and 
   storage mechanisms. Verify that data is correctly uploaded, retrieve objects using proper methods, and address any data integrity 
   issues.

   Recovering deleted objects: If an object is accidentally deleted, you can often recover it using versioning or S3 event notifications.
   Additionally, consider enabling Cross-Region Replication (CRR) for disaster recovery scenarios.
   
restrict-access-to-owner.json - if other persons have s3 full access also we can restrict everyone except owner
---------------------------------------------------------------------------------------------------------------
{
  "Version": "2012-10-17",
  "Id": "RestrictBucketToIAMUsersOnly",
  "Statement": [
    {
      "Sid": "AllowOwnerOnlyAccess",
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:*",
      "Resource": [
        "arn:aws:s3:::your-bucket-name/*",
        "arn:aws:s3:::your-bucket-name"
      ],
      "Condition": {
        "StringNotEquals": {
          "aws:PrincipalArn": "arn:aws:iam::AWS_ACCOUNT_ID:root"
        }
      }
    }
  ]
}

static-website-basic.json - for hosting a website from s3 buckets
------------------------------------------------------------------
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicReadGetObject",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": [
                "arn:aws:s3:::<Bucket-Name>/*"
            ]
        }
    ]
}